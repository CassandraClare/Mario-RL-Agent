{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VLG Mario Project .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FJRjbyWI5uLK",
        "vdWN2EYq54Sy",
        "lsJce4Wi6E-M",
        "xlGdCQbi6JsE"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI96BkYYD08P",
        "outputId": "bb118b6f-62cc-4107-c25f-0554fa1d625c"
      },
      "source": [
        "!pip install gym-super-mario-bros\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym-super-mario-bros\n",
            "  Downloading gym_super_mario_bros-7.3.3-py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting nes-py>=8.1.4\n",
            "  Downloading nes_py-8.1.9.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.21.6)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.5.0)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (4.64.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.21,>=1.4.0->nes-py>=8.1.4->gym-super-mario-bros) (0.16.0)\n",
            "Building wheels for collected packages: nes-py\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.1.9-cp37-cp37m-linux_x86_64.whl size=437573 sha256=38929280c0b2ba32e26bdb12823715b4dd4300eac79cf171de272ddf84a576aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/9e/0284da6e21df2cf30d5ed201fe070a462a3b0e607f7e28efb1\n",
            "Successfully built nes-py\n",
            "Installing collected packages: nes-py, gym-super-mario-bros\n",
            "Successfully installed gym-super-mario-bros-7.3.3 nes-py-8.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mE6MfrCCNT8",
        "outputId": "013f82fd-7a23-4112-d98a-369401f51637"
      },
      "source": [
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
        "import gym\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pickle \n",
        "import numpy as np\n",
        "import collections \n",
        "import cv2\n",
        "import time\n",
        "import statistics\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn.functional as nnf\n",
        "print(torch.cuda.device_count())\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import files\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_2eKR1aDR8C"
      },
      "source": [
        "class SkipAndMax(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4):\n",
        "        \"\"\"\n",
        "          1. Take the same action for 'skip' number of obs\n",
        "          2. Return the max of 2 most recent obs\n",
        "        \"\"\"\n",
        "        super(SkipAndMax, self).__init__(env)\n",
        "        self.obs_buffer = collections.deque(maxlen=2) # 2 most recent observations\n",
        "        self._skip = skip # Use the same action for 'skip' number of obs\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            self.obs_buffer.append(obs)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        # Take max of 2 most recent obs\n",
        "        max_frame = np.max(np.stack(self.obs_buffer), axis=0) \n",
        "\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        self.obs_buffer.clear() # Clear obs buffer\n",
        "        obs = self.env.reset()\n",
        "        self.obs_buffer.append(obs) # Append initial obs\n",
        "        return obs\n",
        "\n",
        "\n",
        "class Frame_Processing(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "      Downsamples to 84x84 => Greyscales\n",
        "    \"\"\"\n",
        "    def __init__(self, env=None):\n",
        "        super(Frame_Processing, self).__init__(env)\n",
        "        old_shape = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8).shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
        "                                                dtype=np.float32)\n",
        "    def observation(self, obs):\n",
        "        obs = Frame_Processing.process(obs)\n",
        "        return np.moveaxis(obs, 2, 0) # Image to Pytorch\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "      \n",
        "        if frame.size == 240 * 256 * 3:\n",
        "            img = np.reshape(frame, [240, 256, 3]).astype(np.float32)\n",
        "        else:\n",
        "            assert False, \"Wrong resolution.\"\n",
        "\n",
        "        # Converting a colored RGB image into a grayscale image\n",
        "        # Formula: Y = 0.299R + 0.587G + 0.114B\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
        "        \n",
        "        # Resize to 84*84\n",
        "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
        "        x_t = resized_screen[18:102, :]\n",
        "        x_t = np.reshape(x_t, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "class BufferingWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super(BufferingWrapper, self).__init__(env)\n",
        "        self.dtype = dtype\n",
        "        old_space = env.observation_space\n",
        "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
        "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
        "\n",
        "    def reset(self):\n",
        "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
        "        return self.observation(self.env.reset())\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer[:-1] = self.buffer[1:]\n",
        "        self.buffer[-1] = observation\n",
        "        return np.array(self.buffer).astype(np.float32) / 255.0 # Normalize pixel values in frame --> 0 to 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KEJV0l1CGTL"
      },
      "source": [
        "\n",
        "class MarioBrossEnvironment:\n",
        "  def __init__(self, skip = 4, buffer_step = 4):\n",
        "      self.env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
        "      self.env = SkipAndMax(self.env)\n",
        "      self.env = Frame_Processing(self.env)\n",
        "      self.env = BufferingWrapper(self.env, 4)\n",
        "      self.env = JoypadSpace(self.env, RIGHT_ONLY) \n",
        "\n",
        "      self.env.seed(500)\n",
        "      self.nb_step = 0\n",
        "      self.observation_space_final = self.env.observation_space.shape\n",
        "      self.action_space = self.env.action_space.n\n",
        "  \n",
        "  def sample_action(self):\n",
        "        return self.env.action_space.sample()\n",
        "\n",
        "  def reset(self):\n",
        "      self.nb_step = 0\n",
        "      state = self.env.reset()\n",
        "      state = torch.unsqueeze(torch.tensor(state),0)\n",
        "      return state\n",
        "\n",
        "  def step(self,action):\n",
        "      state, reward, done, info = self.env.step(action)\n",
        "      state = torch.unsqueeze(torch.tensor(state),0)\n",
        "      return state, reward, done, info\n",
        "\n",
        "  def render(self):\n",
        "        self.env.render()\n",
        "\n",
        "  def close(self):\n",
        "        self.env.close()\n",
        "\n",
        "  def show_state(self,info=\"\"):\n",
        "        plt.figure(3)\n",
        "        plt.clf()\n",
        "        plt.imshow(self.env.render(mode='rgb_array'))\n",
        "        plt.title(\"Episode: %d %s\" % (self.nb_step, info))\n",
        "        plt.axis('off')\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_BhVqMXated"
      },
      "source": [
        "\n",
        "class Classic_ConvNet(nn.Module):\n",
        "  def __init__(self, input_size, n_actions):\n",
        "        super(Classic_ConvNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = n_actions\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.input_size[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        conv_out_size = self.getShapeAfterConvolutions(self.input_size)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.output_size)\n",
        "        )\n",
        "    \n",
        "  def getShapeAfterConvolutions(self, shape):\n",
        "      o = self.conv(torch.zeros(1, *shape))\n",
        "      return int(np.prod(o.size()))\n",
        "\n",
        "  def forward(self, x):\n",
        "      conv_out = self.conv(x)\n",
        "      conv_out=conv_out.view(x.size()[0], -1)\n",
        "      return self.fc(conv_out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsJt7ixIBDD5"
      },
      "source": [
        "\n",
        "class Deeper_ConvNet(nn.Module):\n",
        "  def __init__(self, input_size, n_actions):\n",
        "        super(Deeper_ConvNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = n_actions\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.input_size[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        conv_out_size = self.getShapeAfterConvolutions(self.input_size)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.output_size)\n",
        "        )\n",
        "    \n",
        "  def getShapeAfterConvolutions(self, shape):\n",
        "      o = self.conv(torch.zeros(1, *shape))\n",
        "      return int(np.prod(o.size()))\n",
        "\n",
        "  def forward(self, x):\n",
        "      conv_out = self.conv(x)\n",
        "      conv_out=conv_out.view(x.size()[0], -1)\n",
        "      return self.fc(conv_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAT0Qg2nBl6t"
      },
      "source": [
        "\n",
        "class Wider_ConvNet(nn.Module):\n",
        "  def __init__(self, input_size, n_actions):\n",
        "        super(Wider_ConvNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = n_actions\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.input_size[0], 64, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        conv_out_size = self.getShapeAfterConvolutions(self.input_size)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, self.output_size)\n",
        "        )\n",
        "    \n",
        "  def getShapeAfterConvolutions(self, shape):\n",
        "      o = self.conv(torch.zeros(1, *shape))\n",
        "      return int(np.prod(o.size()))\n",
        "\n",
        "  def forward(self, x):\n",
        "      conv_out = self.conv(x)\n",
        "      conv_out=conv_out.view(x.size()[0], -1)\n",
        "      return self.fc(conv_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXl2wGLnCDSs"
      },
      "source": [
        "\n",
        "class MaxPoolingClassic_ConvNet(nn.Module):\n",
        "  def __init__(self, input_size, n_actions):\n",
        "        super(MaxPoolingClassic_ConvNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = n_actions\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.input_size[0], 32, kernel_size=8, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        conv_out_size = self.getShapeAfterConvolutions(self.input_size)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.output_size)\n",
        "        )\n",
        "    \n",
        "  def getShapeAfterConvolutions(self, shape):\n",
        "      o = self.conv(torch.zeros(1, *shape))\n",
        "      return int(np.prod(o.size()))\n",
        "\n",
        "  def forward(self, x):\n",
        "      conv_out = self.conv(x)\n",
        "      conv_out=conv_out.view(x.size()[0], -1)\n",
        "      return self.fc(conv_out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPjMSSlKHIjp"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, \n",
        "                 model_base,  # resnet backbone\n",
        "                 input_size,\n",
        "                 n_actions,\n",
        "                 trainable_features=True # whether training the feature extractor\n",
        "                 ):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.output_size = n_actions\n",
        "\n",
        "        self.trainable_features = trainable_features\n",
        "\n",
        "        # Initial conv\n",
        "        self.conv_home = nn.Conv2d(self.input_size[0], 3, kernel_size=1, stride=1)\n",
        "        \n",
        "        # For colors, see the picture of resnet\n",
        "        # Orange \n",
        "        self.conv1 = model_base.conv1\n",
        "        self.bn1 = model_base.bn1\n",
        "        self.relu = model_base.relu\n",
        "        self.maxpool = model_base.maxpool\n",
        "\n",
        "        # Purple\n",
        "        self.layer1 = model_base.layer1\n",
        "        \n",
        "        # Green\n",
        "        self.layer2 = model_base.layer2\n",
        "\n",
        "        # Red \n",
        "        self.layer3 = model_base.layer3\n",
        "\n",
        "        # Blue\n",
        "        self.layer4 = model_base.layer4\n",
        "        \n",
        "\n",
        "        # Grey\n",
        "        self.avgpool = model_base.avgpool\n",
        "\n",
        "        # Feature extractor\n",
        "        self.feature_layers = nn.Sequential(self.conv_home, self.conv1, self.bn1, self.relu, self.maxpool, \n",
        "                                            self.layer1, self.layer2, self.layer3, self.layer4, \n",
        "                                            self.avgpool)\n",
        "        \n",
        "        self.fc = nn.Linear(model_base.fc.in_features, self.output_size)\n",
        "        self.__in_features = model_base.fc.in_features\n",
        "\n",
        "    def forward(self, x): # TODO\n",
        "        features = self.feature_layers(x) # TODO\n",
        "        features = features.view(features.size(0), -1)\n",
        "        y = self.fc(features) # TODO\n",
        "        return y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwvBJpbKdldf"
      },
      "source": [
        "class DeepQNetworkAgent:\n",
        "  def __init__(self, model,env, double, resnet_pretrained = None, test_epoch = 50):\n",
        "    \n",
        "    # Environment attributes\n",
        "    self.env=env\n",
        "    self.num_actions = self.env.action_space\n",
        "    self.state_shape = self.env.observation_space_final\n",
        "    self.test_epoch = test_epoch\n",
        "    \n",
        "    # Agent parameters\n",
        "    self.gamma = None\n",
        "    self.eps = None\n",
        "    self.eps_min = None\n",
        "    self.eps_decay = None\n",
        "    self.double = double\n",
        "    self.end_position = 0\n",
        "\n",
        "    # Double Neural Networks\n",
        "    if resnet_pretrained == None:\n",
        "      self.online_net = model(self.state_shape,self.num_actions)\n",
        "      self.target_net = model(self.state_shape,self.num_actions)\n",
        "    else:\n",
        "      self.online_net = model(resnet_pretrained,self.state_shape,self.num_actions)\n",
        "      self.target_net = model(resnet_pretrained,self.state_shape,self.num_actions)\n",
        "    \n",
        "    # Neural Networks parameters  \n",
        "    self.optimizer = None\n",
        "    self.loss = None\n",
        "    self.cuda = False\n",
        "    self.train_loader = None\n",
        "    self.weight_decay = None\n",
        "    self.lr = None\n",
        "    self.dropout = None\n",
        "\n",
        "    # Experiences memory\n",
        "    self.memory_size = None\n",
        "    self.mem_element = 0\n",
        "    self.mem_state = None\n",
        "    self.mem_nextstate = None\n",
        "    self.mem_reward = None\n",
        "    self.mem_action = None\n",
        "    self.mem_done = None\n",
        "    self.batch_size = None   \n",
        "\n",
        "  def compile(self, optimizer, loss, \n",
        "              gamma, memory_size, batch_size, eps_max, eps_min, eps_decay, copy_model , \n",
        "              dropout = 0.05,lr=0.001, weight_decay=0.001, cuda=True):\n",
        "    self.loss = loss()\n",
        "    self.gamma = gamma\n",
        "    self.memory_size = memory_size\n",
        "    self.batch_size = batch_size   \n",
        "    self.eps = eps_max\n",
        "    self.eps_max = eps_max\n",
        "    self.eps_min = eps_min\n",
        "    self.eps_decay = eps_decay\n",
        "    self.copy_model = copy_model\n",
        "    self.total_iter = 0\n",
        "    self.dropout = dropout\n",
        "    self.weight_decay = weight_decay\n",
        "    self.lr = lr\n",
        "    self.cuda = cuda\n",
        "\n",
        "    # Initialize the memory\n",
        "    self.mem_state = torch.zeros(self.memory_size, *self.state_shape).float()\n",
        "    self.mem_nextstate = torch.zeros(self.memory_size, *self.state_shape).float()\n",
        "    self.mem_reward = torch.zeros(self.memory_size, 1).float()\n",
        "    self.mem_action = torch.zeros(self.memory_size, 1).float()\n",
        "    self.mem_done = torch.zeros(self.memory_size, 1).float()\n",
        "\n",
        "    try: \n",
        "      self.optimizer = optimizer(params=self.online_net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    except:\n",
        "      print('Requires the creation of a model')    \n",
        "\n",
        "    if self.cuda:\n",
        "      self.online_net = self.online_net.cuda()\n",
        "      self.target_net = self.target_net.cuda()  \n",
        "\n",
        "  def act(self, state):\n",
        "    if self.cuda:\n",
        "      state = state.cuda().float()\n",
        "    else:\n",
        "      state = state.float()\n",
        "\n",
        "    # Choose exploration or exploitation\n",
        "    if random.random() < self.eps:\n",
        "      #Exploration\n",
        "      return random.randint(0,self.num_actions-1)\n",
        "    # Exploitation\n",
        "    if self.double:\n",
        "      return torch.argmax(self.online_net(state)).item()\n",
        "    else:\n",
        "      return torch.argmax(self.target_net(state)).item()\n",
        "\n",
        "  def train_step(self,state_batch,nextstate_batch,reward_batch,\n",
        "                 action_batch,done_batch):\n",
        "    \n",
        "    self.optimizer.zero_grad()\n",
        "    ## Use GPU\n",
        "    if self.cuda:\n",
        "      state_batch = state_batch.cuda()\n",
        "      nextstate_batch = nextstate_batch.cuda()\n",
        "      reward_batch = reward_batch.cuda()\n",
        "      action_batch = action_batch.cuda()\n",
        "      done_batch = done_batch.cuda()\n",
        "    \n",
        "    ## Double DQN Learning: decouple selection with online_net and evaluation with target_net\n",
        "    if self.double:\n",
        "      selection = torch.argmax(self.online_net(nextstate_batch), dim = 1).unsqueeze(1)\n",
        "      evaluation = self.target_net(nextstate_batch).gather(1, selection.long())\n",
        "      target = reward_batch + torch.mul(self.gamma *  evaluation, 1 - done_batch).float()\n",
        "    ## DQN Learning: all is calculated with target_net\n",
        "    else:\n",
        "      target = reward_batch + torch.mul((self.gamma * \n",
        "                  self.target_net(nextstate_batch).max(1).values.unsqueeze(1)), \n",
        "                  1 - done_batch).float()\n",
        "    \n",
        "    actual = self.online_net(state_batch).gather(1, action_batch.long()).float() \n",
        "    # calculate the loss of the target (new rewards) and actual (calculated with online net)\n",
        "    loss = self.loss(target , actual)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "\n",
        "  def experience_replay(self):\n",
        "    # Experience replay:  get a sample from all the memory and train\n",
        "    min_sample = min(self.batch_size,self.mem_element)\n",
        "    sample_batch = random.choices(range(self.mem_element), k=min_sample)\n",
        "    state_batch = self.mem_state[sample_batch]\n",
        "    nextstate_batch = self.mem_nextstate[sample_batch]\n",
        "    reward_batch = self.mem_reward[sample_batch]\n",
        "    action_batch = self.mem_action[sample_batch]\n",
        "    done_batch = self.mem_done[sample_batch]\n",
        "\n",
        "    self.train_step(state_batch,nextstate_batch,reward_batch,\n",
        "                 action_batch,done_batch)\n",
        "\n",
        "  def update(self,state,action , nextstate, reward,done):\n",
        "\n",
        "    ## Update memory with new values\n",
        "    self.mem_state[self.end_position] = state.float()\n",
        "    self.mem_nextstate[self.end_position] = nextstate.float()\n",
        "    self.mem_reward[self.end_position] = torch.tensor([reward]).unsqueeze(0).float()\n",
        "    self.mem_action[self.end_position] = torch.tensor([action]).unsqueeze(0).float()\n",
        "    self.mem_done[self.end_position] = torch.tensor([done]).unsqueeze(0).float()\n",
        "\n",
        "    self.end_position = (self.end_position + 1) % self.memory_size  # FIFO tensor\n",
        "    self.mem_element = min(self.mem_element + 1, self.memory_size)\n",
        "\n",
        "\n",
        "    # Update the target_net with the parameters of the online_net\n",
        "    if self.total_iter % self.copy_model == 0:\n",
        "            self.transferParameters()\n",
        "    #  Train the model with experience replay\n",
        "    if self.mem_element>=self.batch_size:\n",
        "      self.experience_replay()\n",
        "    \n",
        "    self.total_iter+=1\n",
        "\n",
        "  def run(self, epochs, max_iter = 500):\n",
        "    #List of rewards per epoch\n",
        "    list_rewards = []\n",
        "    list_test_rewards = []\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "      time_act = 0\n",
        "      time_get_env = 0\n",
        "      time_update = 0\n",
        "      time_total = 0\n",
        "      state = self.env.reset()\n",
        "      epoch_reward = 0\n",
        "      iter = 0\n",
        "      while True:\n",
        "        start_0 = time.time()\n",
        "        # select best action\n",
        "        action = self.act(state)\n",
        "        time_act += time.time() - start_0\n",
        "        start_1 = time.time()\n",
        "        # Apply action and get new state and rewards\n",
        "        nextstate, reward, done, info = self.env.step(action)\n",
        "        time_get_env += time.time() - start_1\n",
        "        start_2 = time.time()\n",
        "        # Update the model with the last interaction\n",
        "        self.update(state,action , nextstate, reward,done)\n",
        "        time_update += time.time() - start_2\n",
        "        # Move to the next state\n",
        "        state = torch.tensor(nextstate)\n",
        "        epoch_reward+=reward\n",
        "        iter+=1\n",
        "        time_total += time.time() - start_0\n",
        "        # If Mario died or we won, finish the epoch\n",
        "        if done or iter>=max_iter:\n",
        "          break\n",
        "\n",
        "      # Decay the eps every 2 epochs\n",
        "      if epoch>0 and epoch%2 == 0:\n",
        "        self.eps *= self.eps_decay\n",
        "        self.eps = max(self.eps, self.eps_min)\n",
        "        print(\"eps = \", self.eps)\n",
        "\n",
        "      # Test the performance of the net each test_epoch (without exploration)\n",
        "      if epoch>0 and epoch%self.test_epoch == 0:\n",
        "        test_rewards = self.test(4,4000,False)\n",
        "        list_test_rewards.append(test_rewards)\n",
        "\n",
        "      list_rewards.append(epoch_reward)\n",
        "      print(\"\")\n",
        "      print(\"Reward: \", epoch_reward)\n",
        "      #print(\"Avg_time_getenv: \", time_get_env)\n",
        "      #print(\"Avg_time_update: \", time_update)\n",
        "      #print(\"Avg_time_total: \", time_total)\n",
        "\n",
        "    return (list_rewards,list_test_rewards)\n",
        "\n",
        "  def transferParameters(self):\n",
        "    self.target_net.load_state_dict(self.online_net.state_dict())\n",
        "\n",
        "  def test(self, epochs = 50, maxiter = 1000, show = False, eps_test = 0.01):\n",
        "    # Set exploration eps as 0 to evaluate only the model performance\n",
        "    eps_old = self.eps\n",
        "    self.eps = eps_test\n",
        "    list_rewards = []\n",
        "    done = True\n",
        "    for ep in range(epochs):\n",
        "      epoch_reward = 0\n",
        "      for step in range(maxiter):\n",
        "          if done:\n",
        "              state = self.env.reset()\n",
        "          action = self.act(state)\n",
        "          nextstate, reward, done, info = self.env.step(action)\n",
        "          epoch_reward+=reward\n",
        "          state = torch.tensor(nextstate)\n",
        "          if show:\n",
        "            self.env.show_state()\n",
        "          if done:\n",
        "            break\n",
        "      list_rewards.append(epoch_reward)\n",
        "    self.eps = eps_old\n",
        "    return list_rewards\n",
        "\n",
        "  # Save model to reuse it later\n",
        "  def saveParameters(self, path):\n",
        "    torch.save(self.online_net.state_dict(), path)\n",
        "    \n",
        "  # Load parameters from a pretrained model.\n",
        "  def pretrainedParameters(self, path):\n",
        "    self.online_net.load_state_dict(torch.load(path))\n",
        "    self.target_net.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mario = MarioBrossEnvironment()\n",
        "agent = DeepQNetworkAgent(Classic_ConvNet, mario, double = True)\n",
        "agent.compile( optimizer = torch.optim.Adam, loss = nn.SmoothL1Loss, \n",
        "              gamma = 0.9, memory_size = 10000, batch_size = 32, \n",
        "              eps_max = 1, eps_min = 0.02, lr = 0.00025, eps_decay = 0.99, copy_model = 5000)\n",
        "## The agent learns here!!\n",
        "rewards,test_rewards_run = agent.run(5000, 4000)"
      ],
      "metadata": {
        "id": "WMp2ICxzJX72",
        "outputId": "87115da1-f0c1-4dc6-afe9-68138afc7165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  0%|          | 1/5000 [00:06<9:05:22,  6.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reward:  718.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/5000 [00:09<6:07:43,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reward:  637.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/5000 [00:10<3:43:24,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eps =  0.99\n",
            "\n",
            "Reward:  244.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 4/5000 [00:23<9:36:34,  6.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reward:  706.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 5/5000 [00:25<7:04:16,  5.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eps =  0.9801\n",
            "\n",
            "Reward:  603.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 6/5000 [00:26<4:59:47,  3.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reward:  229.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "bKlDIzhpfHg5",
        "outputId": "ea4c2a5c-3c56-4a1e-eb4d-49c25279c0ab"
      },
      "source": [
        "name_doubleDQN = \"DoubleDQN_Classic\"\n",
        "doubleDQN_pd = pd.read_csv('DoubleDQN.csv',header = None)\n",
        "pd_data = doubleDQN_pd\n",
        "pd_data.columns = [name_doubleDQN]\n",
        "\n",
        "pd_data = pd_data.reset_index()\n",
        "bines = [(i) * 50 for i in list(range(101))]\n",
        "bines_lab = [(i) * 50 for i in list(range(100))]\n",
        "pd_data['binned'] = pd.cut(pd_data['index'], bins=bines, labels=bines_lab)\n",
        "pd_data = pd_data.fillna(0)\n",
        "datag = pd_data.groupby(['binned']).mean()\n",
        "datag = datag.reset_index()\n",
        "dataq_min = pd_data.groupby(['binned']).quantile(.10)\n",
        "dataq_min = dataq_min.reset_index()\n",
        "dataq_max = pd_data.groupby(['binned']).quantile(.90)\n",
        "dataq_max = dataq_max.reset_index()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(np.array(datag['binned']),np.array(datag[name_doubleDQN]))\n",
        "ax.fill_between(datag['binned'], dataq_min[name_doubleDQN], dataq_max[name_doubleDQN], alpha=.3)\n",
        "\n",
        "ax.set_xlabel(\"Training episodes\")\n",
        "ax.set_ylabel(\"Reward\")\n",
        "\n",
        "ax.set_title('Double DQN rewards', fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgF5K3XMpEB9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "6322e613-fd6d-47d1-e54b-67ee98ac9698"
      },
      "source": [
        "## Test without exploration - only model performance\n",
        "test_rewards = agent.test(50,4000,False, eps_test = 0)\n",
        "agent.test(1,4000,True)\n",
        "print(\"Average reward: \", statistics.mean(test_rewards))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:230: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-365d59017562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Test without exploration - only model performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average reward: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4e42c72293bc>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, epochs, maxiter, show, eps_test)\u001b[0m\n\u001b[1;32m    226\u001b[0m               \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m           \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m           \u001b[0mnextstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m           \u001b[0mepoch_reward\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m           \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7cfac38ba34c>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nes_py/wrappers/joypad_space.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# take the step and record the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-99105a1599ff>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nes_py/nes_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrollers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;31m# pass the action to the emulator as an unsigned byte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# get the reward for this step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6awaRgr_JJnq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}